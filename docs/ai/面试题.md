# AI 相关的面试题

## 问题 1：LLM 出现幻觉（Hallucination）的深层原因是什么

- **语言模型是概率模型，不是事实模型**：LLM 的本质是“预测下一个最可能的词”，不是在“查找真相”，而是在生成语言模式。当输入提示不明确或知识缺失时，会凭统计相关性“合理地编造”。
- **训练数据中存在噪声和虚假样本**：大模型学习了互联网上的海量文本，而这些内容本身可能包含错误或臆测信息。模型学到这些偏差后，在回答中会自然复现。
- **缺乏事实验证机制**：模型输出结果时不会自动校验真伪，也不会访问实时数据。在多轮推理中，错误会被“递进强化”——尤其是 Agent 模式下的反射循环，会放大错误逻辑。
- **Prompt 上下文过短或缺乏约束**：当上下文被截断、知识片段不完整，模型会自动“补空缺”，生成符合语义但不符合事实的回答。
- **任务模糊或目标歧义**：如果任务没有明确评价标准，模型会更倾向于填补内容空白，从而编造细节。

## 问题 2：RAG（检索增强生成）是什么？

RAG（Retrieval-Augmented Generation）是当前企业级 AI 应用最核心的架构思路之一。让模型“具备最新知识”，而不依赖模型固有训练语料。

1. **文档嵌入（Embedding）**
   - 把知识库（PDF、Markdown、数据库内容等）切成小块（Chunk），
   - 然后用 `Embedding Model`（如 `text-embedding-3-large` 或 `bge-m3`）将文本转为高维向量。
2. **向量检索（Vector Search）**
   - 用户提问时，将 Query 也转成向量。
   - 计算 Query 向量与文档向量的相似度。
   - 检索出最相关的若干段落。
3. **增强生成（Augmented Generation）**
   - 把检索结果拼入 Prompt 的上下文中。
   - 交由 LLM 生成最终回答。
